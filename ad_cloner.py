"""
Ad Cloner - Main Orchestrator
Combines all modules to clone ads with aggression variations
"""
import json
import time
from pathlib import Path
from typing import Dict, List, Optional

from config import Config
from modules.gemini_analyzer import GeminiVideoAnalyzer
from modules.sora_transformer import SoraAdTransformer
from modules.aggression_variants import AggressionVariantGenerator
from modules.sora_prompt_builder import SoraPromptBuilder
from modules.sora_client import SoraClient
from modules.video_assembler import VideoAssembler
from modules.ad_evaluator import AdEvaluator
from modules.prompt_validator import PromptValidator
from modules.utils import normalize_spokesperson
from pipeline_integrator import PipelineIntegrator


class AdCloner:
    """Main orchestrator for ad cloning pipeline"""

    def __init__(self, logger=None, spaces_client=None, session_id=None, generation_id=None, integrator=None):
        """
        Initialize all components

        Args:
            logger: Optional logger for web interface
            spaces_client: Optional SpacesClient for cloud uploads
            session_id: Optional session ID for organizing uploads
            generation_id: Optional generation ID for history tracking
            integrator: Optional PipelineIntegrator for saving generation history
        """
        print("Initializing Ad Cloner...")
        Config.validate_api_keys()

        self.analyzer = GeminiVideoAnalyzer()
        self.transformer = SoraAdTransformer()  # Transform ads for Sora
        self.variant_generator = AggressionVariantGenerator()
        self.prompt_builder = SoraPromptBuilder()  # Build Sora prompts (active)
        self.prompt_validator = PromptValidator()  # Validate before API calls
        self.sora_client = SoraClient(spaces_client=spaces_client, session_id=session_id)
        self.assembler = VideoAssembler()
        self.evaluator = AdEvaluator()  # Evaluate generated ads
        self.logger = logger  # Optional logger for web interface
        self.generation_id = generation_id  # Generation ID for history tracking
        self.integrator = integrator  # PipelineIntegrator for saving history

        print("âœ“ All systems ready\n")

    def clone_ad(self, video_path: str, variants: Optional[List[str]] = None) -> Dict:
        """
        Complete ad cloning pipeline

        Args:
            video_path: Path to winning ad video
            variants: Optional list of variant levels to generate
                     (default: all 4 - soft, medium, aggressive, ultra)

        Returns:
            Results dictionary with all generated ads
        """
        start_time = time.time()

        print("="*70)
        print("AD CLONER PIPELINE")
        print("="*70)
        print(f"Input Video: {video_path}\n")

        # STEP 1: Analyze video with Gemini
        print("\n[1/5] Analyzing video with Gemini 2.5...")
        if self.logger:
            from modules.logger import LogLevel
            self.logger.start_stage('analysis')
            self.logger.log(LogLevel.INFO, "Starting Gemini video analysis", {'video_path': video_path})
            self.logger.log(LogLevel.VERBOSE, "Uploading video to Gemini File API", {})

        try:
            analysis, analysis_path = self.analyzer.analyze_and_save(video_path)
            print(f"âœ“ Analysis complete: {analysis_path}")

            # Save analysis metadata to generation history
            if self.integrator and self.generation_id:
                self.integrator.save_analysis_metadata(self.generation_id, analysis)

            if self.logger:
                self.logger.log(LogLevel.VERBOSE, "Video analysis completed", {'analysis_path': analysis_path})

            # Extract spokesperson description (normalize list/dict formats)
            spokesperson = normalize_spokesperson(analysis)
            spokesperson_desc = spokesperson.get('physical_description', 'person')
            print(f"\nSpokesperson: {spokesperson_desc[:100]}...")

            if self.logger:
                num_scenes = len(analysis.get('scene_breakdown', []))
                scene_info = {
                    'scenes': num_scenes,
                    'path': analysis_path,
                    'duration': analysis.get('video_metadata', {}).get('duration_seconds', 0),
                    'spokesperson_length': len(spokesperson_desc)
                }
                self.logger.log(LogLevel.VERBOSE, f"Detected {num_scenes} scenes in video", scene_info)

                # Log each scene
                for i, scene in enumerate(analysis.get('scene_breakdown', []), 1):
                    self.logger.log(LogLevel.VERBOSE, f"Scene {i}: {scene.get('timestamp')} - {scene.get('purpose')}", {
                        'timestamp': scene.get('timestamp'),
                        'duration': scene.get('duration_seconds'),
                        'purpose': scene.get('purpose')
                    })

                self.logger.complete_stage('analysis', scene_info)

        except Exception as e:
            if self.logger:
                self.logger.log(LogLevel.ERROR, f"Gemini analysis failed: {str(e)}", {
                    'error': str(e),
                    'error_type': type(e).__name__,
                    'video_path': video_path
                })
                self.logger.fail_stage('analysis', str(e))
            raise

        # STEP 1.5: Transform to Sora-friendly structure
        print("\n[1.5/5] Transforming ad structure for Sora...")
        if self.logger:
            self.logger.log(LogLevel.INFO, "Detecting ad vertical and transforming structure", {})

        try:
            # Detect vertical
            vertical = self.transformer.detect_vertical(analysis)
            vertical_name = vertical.replace('_', ' ').title()

            print(f"âœ“ Detected vertical: {vertical_name}")

            if self.logger:
                self.logger.log(LogLevel.VERBOSE, f"Vertical detected: {vertical_name}", {
                    'vertical': vertical,
                    'vertical_name': vertical_name
                })

            # Transform structure
            transformed_scenes = self.transformer.transform_to_sora_structure(analysis, vertical)

            print(f"âœ“ Transformed to Sora-friendly structure:")
            print(f"  - {sum(1 for s in transformed_scenes if s.get('has_character'))} character scene(s)")
            print(f"  - {sum(1 for s in transformed_scenes if not s.get('has_character'))} B-roll scene(s)")

            if self.logger:
                for scene in transformed_scenes:
                    scene_type = "CHARACTER" if scene.get('has_character') else "B-ROLL"
                    self.logger.log(LogLevel.VERBOSE, f"Scene {scene['scene_number']}: {scene_type} - {scene['type']}", {
                        'scene': scene['scene_number'],
                        'type': scene['type'],
                        'has_character': scene.get('has_character', False),
                        'duration': scene['duration_seconds']
                    })

            # Replace original scene_breakdown with transformed scenes
            analysis['scene_breakdown'] = transformed_scenes
            analysis['vertical'] = vertical
            analysis['vertical_name'] = vertical_name
            analysis['transformed'] = True

            # Save transformation metadata to generation history
            if self.integrator and self.generation_id:
                self.integrator.save_transformation_metadata(self.generation_id, {
                    'vertical': vertical,
                    'vertical_name': vertical_name,
                    'transformed_scenes': transformed_scenes
                })

        except Exception as e:
            if self.logger:
                self.logger.log(LogLevel.ERROR, f"Transformation failed: {str(e)}", {
                    'error': str(e),
                    'error_type': type(e).__name__
                })
            # Continue with original analysis if transformation fails
            print(f"âš  Transformation failed, using original structure: {str(e)}")

        # STEP 2: Generate aggression variants
        print("\n[2/5] Generating aggression variants...")
        if self.logger:
            self.logger.start_stage('variants')
            self.logger.log(LogLevel.VERBOSE, "Generating aggression level variations", {
                'requested_variants': variants if variants else 'all'
            })

        try:
            all_variants = self.variant_generator.generate_variants(analysis)

            # Filter variants if specified
            if variants:
                original_count = len(all_variants)
                all_variants = [v for v in all_variants if v['variant_level'] in variants]
                if self.logger:
                    self.logger.log(LogLevel.VERBOSE, f"Filtered variants: {original_count} â†’ {len(all_variants)}", {
                        'requested': variants,
                        'generated': [v['variant_level'] for v in all_variants]
                    })

            print(f"âœ“ Generated {len(all_variants)} variants")
            for v in all_variants:
                print(f"  - {v['variant_name']}")
                if self.logger:
                    self.logger.log(LogLevel.VERBOSE, f"Variant: {v['variant_name']}", {
                        'level': v['variant_level'],
                        'scenes': len(v.get('modified_scenes', []))
                    })

            if self.logger:
                self.logger.complete_stage('variants', {
                    'count': len(all_variants),
                    'levels': [v['variant_level'] for v in all_variants]
                })

        except Exception as e:
            if self.logger:
                self.logger.log(LogLevel.ERROR, f"Variant generation failed: {str(e)}", {
                    'error': str(e),
                    'error_type': type(e).__name__
                })
                self.logger.fail_stage('variants', str(e))
            raise

        # STEP 3: Build Sora prompts from transformer scenes (DIRECT - no AI Director)
        print("\n[3/5] Building Sora prompts from extreme hooks...")
        if self.logger:
            self.logger.start_stage('prompts')
            self.logger.log(LogLevel.VERBOSE, "Building prompts directly from transformer scenes (extreme hooks)", {})

        try:
            variant_prompts = {}

            for variant in all_variants:
                if self.logger:
                    self.logger.log(LogLevel.VERBOSE, f"Building prompts for {variant['variant_name']}", {
                        'variant_level': variant['variant_level'],
                        'num_scenes': len(variant.get('modified_scenes', []))
                    })

                # Build prompts DIRECTLY from transformer scenes (with extreme hooks)
                print(f"  ðŸŽ¬ Building {variant['variant_name']} prompts...")

                # Extract spokesperson and script from analysis (normalize spokesperson format)
                spokesperson = normalize_spokesperson(analysis)
                spokesperson_desc = spokesperson.get('physical_description', 'person')
                full_script = analysis.get('script', {}).get('full_transcript', '')

                # Build prompts using SoraPromptBuilder (handles extreme hooks + actors)
                composed_prompts = self.prompt_builder.build_all_scene_prompts(
                    variant,
                    spokesperson_desc,
                    full_script
                )
                
                # VALIDATE prompts before storing
                validation_report = self.prompt_validator.validate_all_prompts(composed_prompts)
                
                if validation_report['errors_count'] > 0:
                    print(f"âš  Warning: {validation_report['errors_count']} validation errors found")
                    if self.logger:
                        self.logger.log(LogLevel.WARNING, f"Prompt validation found {validation_report['errors_count']} errors", {
                            'variant': variant['variant_level'],
                            'errors': validation_report['errors_count'],
                            'warnings': validation_report['warnings_count']
                        })
                
                # Show validation warnings in console
                if validation_report['warnings_count'] > 0:
                    print(f"  âš¡ {validation_report['warnings_count']} optimization suggestions")
                
                variant_prompts[variant['variant_level']] = composed_prompts
                print(f"âœ“ {variant['variant_name']}: {len(composed_prompts)} scenes (audio + text + effects)")

                # Log AI-generated prompts for debugging
                if self.logger:
                    for i, prompt_data in enumerate(composed_prompts, 1):
                        self.logger.log(LogLevel.VERBOSE, f"  Scene {i} AI-generated prompt ready", {
                            'scene': i,
                            'timestamp': prompt_data.get('timestamp'),
                            'prompt_length': len(prompt_data['prompt']),
                            'full_prompt': prompt_data['prompt'],  # Log FULL prompt
                            'scene_type': prompt_data.get('scene_type'),
                            'purpose': prompt_data.get('purpose'),
                            'has_audio': prompt_data.get('has_audio'),
                            'has_text': prompt_data.get('has_text'),
                            'text_count': prompt_data.get('text_count', 0),
                            'composition_method': 'extreme_hooks_direct'
                        })

            # Save all prompts to file for detailed inspection
            prompts_file = Path(analysis_path).parent / f"sora_prompts_{Path(analysis_path).stem}.json"
            with open(prompts_file, 'w') as f:
                json.dump(variant_prompts, f, indent=2)
            print(f"âœ“ All prompts saved to: {prompts_file}")

            # Save prompts metadata and create scene records in generation history
            if self.integrator and self.generation_id:
                self.integrator.save_prompts_metadata(self.generation_id, variant_prompts)

                # Create scene records for each variant
                self.variant_scene_ids = {}  # Store scene IDs for later use
                for variant_level, prompts in variant_prompts.items():
                    scene_ids = self.integrator.create_scene_records(
                        self.generation_id,
                        variant_level,
                        [p['prompt'] for p in prompts]
                    )
                    self.variant_scene_ids[variant_level] = scene_ids

            if self.logger:
                total_scenes = sum(len(p) for p in variant_prompts.values())
                self.logger.complete_stage('prompts', {
                    'total_scenes': total_scenes,
                    'variants': list(variant_prompts.keys()),
                    'prompts_file': str(prompts_file),
                    'composition_type': 'extreme_hooks_direct',
                    'features': ['extreme_hooks', 'transformer_scenes', 'audio', 'text_overlays', 'visual_progression'],
                    'validated': True
                })

        except Exception as e:
            if self.logger:
                self.logger.log(LogLevel.ERROR, f"Prompt composition failed: {str(e)}", {
                    'error': str(e),
                    'error_type': type(e).__name__
                })
                self.logger.fail_stage('prompts', str(e))
            raise

        # STEP 4: Generate videos with Sora (parallel)
        print("\n[4/5] Generating videos with Sora...")
        print(f"Total scenes to generate: {sum(len(p) for p in variant_prompts.values())}")
        print(f"This will take approximately 15-20 minutes...\n")

        if self.logger:
            total_scenes = sum(len(p) for p in variant_prompts.values())
            self.logger.start_stage('generation', total_scenes)
            self.logger.log(LogLevel.INFO, f"Starting Sora generation: {total_scenes} scenes across {len(variant_prompts)} variants", {
                'total_scenes': total_scenes,
                'variants': list(variant_prompts.keys())
            })

        try:
            generated_variants = {}

            for variant_level, prompts in variant_prompts.items():
                if self.logger:
                    self.logger.track_variant(variant_level, 'generating')
                    self.logger.log(LogLevel.VERBOSE, f"Starting {variant_level} variant generation", {
                        'variant': variant_level,
                        'scenes': len(prompts),
                        'method': 'parallel'
                    })

                try:
                    result = self.sora_client.generate_variant_parallel(prompts, variant_level)
                    generated_variants[variant_level] = result

                    # Process and save videos to Spaces if generation succeeded
                    if result['success'] and self.integrator and self.generation_id:
                        scene_ids = self.variant_scene_ids.get(variant_level, [])
                        scenes = result.get('scenes', [])

                        for idx, scene_data in enumerate(scenes):
                            if idx < len(scene_ids):
                                scene_id = scene_ids[idx]
                                sora_video_id = scene_data.get('video_id')
                                sora_content_url = scene_data.get('content_url')

                                if sora_video_id and sora_content_url:
                                    # Process video: download, generate thumbnail, upload to Spaces
                                    self.integrator.process_sora_video(
                                        scene_id,
                                        sora_video_id,
                                        sora_content_url,
                                        self.generation_id,
                                        variant_level,
                                        idx + 1  # scene_number (1-indexed)
                                    )

                    if self.logger:
                        status = 'completed' if result['success'] else 'failed'
                        self.logger.track_variant(variant_level, status, result)
                        self.logger.log(LogLevel.VERBOSE, f"Variant {variant_level} generation {status}", {
                            'variant': variant_level,
                            'success': result['success'],
                            'scenes_completed': len(result.get('scenes', []))
                        })

                except Exception as e:
                    if self.logger:
                        self.logger.log(LogLevel.ERROR, f"Sora generation failed for {variant_level}: {str(e)}", {
                            'variant': variant_level,
                            'error': str(e),
                            'error_type': type(e).__name__
                        })
                        self.logger.track_variant(variant_level, 'failed', {'error': str(e)})
                    generated_variants[variant_level] = {'success': False, 'error': str(e)}

            if self.logger:
                successful = sum(1 for v in generated_variants.values() if v.get('success'))
                self.logger.complete_stage('generation', {
                    'total_variants': len(generated_variants),
                    'successful': successful,
                    'failed': len(generated_variants) - successful
                })

        except Exception as e:
            if self.logger:
                self.logger.log(LogLevel.ERROR, f"Generation stage failed: {str(e)}", {
                    'error': str(e),
                    'error_type': type(e).__name__
                })
                self.logger.fail_stage('generation', str(e))
            raise

        # STEP 5: Assemble final videos
        print("\n[5/5] Assembling final ads...")
        if self.logger:
            self.logger.start_stage('assembly')

        final_ads = {}

        for variant_level, variant_result in generated_variants.items():
            if variant_result['success']:
                try:
                    final_path = self.assembler.assemble_variant(variant_result)
                    final_ads[variant_level] = final_path
                    print(f"âœ“ {variant_level.UPPER()}: {final_path}")
                except Exception as e:
                    print(f"âœ— Failed to assemble {variant_level}: {e}")
            else:
                print(f"âœ— Skipping {variant_level} (generation failed)")

        if self.logger:
            self.logger.complete_stage('assembly', {'videos': len(final_ads)})

        # STEP 6: Evaluate generated ads (NEW)
        print("\n[6/6] Evaluating generated ads...")
        evaluations = {}

        for variant_level, video_path in final_ads.items():
            try:
                print(f"\nâ–¸ Evaluating {variant_level} variant...")

                # Get the prompts used for this variant
                prompts_used = variant_prompts.get(variant_level, [])

                # Evaluate
                evaluation = self.evaluator.evaluate_generated_ad(
                    video_path,
                    analysis,
                    prompts_used
                )

                evaluations[variant_level] = evaluation

                # Save evaluation report
                eval_path = Path(analysis_path).parent / f"evaluation_{variant_level}.json"
                self.evaluator.save_evaluation_report(evaluation, str(eval_path))

                # Print ratings
                ratings = evaluation.get('ratings', {})
                print(f"  Overall Score: {ratings.get('overall_score', 0):.1f}/10")
                print(f"  Prediction: {ratings.get('predicted_performance', 'Unknown')}")

                # Save evaluation metadata to generation history
                if self.integrator and self.generation_id:
                    self.integrator.save_evaluation_metadata(self.generation_id, evaluations)

                if self.logger:
                    self.logger.log(LogLevel.INFO, f"Evaluated {variant_level}: {ratings.get('overall_score', 0):.1f}/10", {
                        'variant': variant_level,
                        'score': ratings.get('overall_score', 0),
                        'prediction': ratings.get('predicted_performance', 'Unknown'),
                        'eval_path': str(eval_path)
                    })

            except Exception as e:
                print(f"  âœ— Evaluation failed: {e}")
                if self.logger:
                    self.logger.log(LogLevel.WARNING, f"Evaluation failed for {variant_level}: {str(e)}", {
                        'variant': variant_level,
                        'error': str(e)
                    })

        # Summary
        elapsed = time.time() - start_time
        print("\n" + "="*70)
        print("PIPELINE COMPLETE")
        print("="*70)
        print(f"Time elapsed: {elapsed/60:.1f} minutes")
        print(f"Ads generated: {len(final_ads)}")
        print("\nFinal ads:")
        for level, path in final_ads.items():
            score = evaluations.get(level, {}).get('ratings', {}).get('overall_score', 0)
            print(f"  {level.upper()}: {path} (Score: {score:.1f}/10)")

        # Mark generation as completed in history
        if self.integrator and self.generation_id:
            try:
                # Calculate actual cost (4 scenes per variant * $0.32/scene)
                actual_cost = len(final_ads) * 4 * Config.SORA_2_PRO_COST_PER_SECOND * 12  # 12 seconds per scene
                self.integrator.gen_manager.update_generation_status(
                    self.generation_id,
                    'completed',
                    actual_cost=actual_cost
                )
                print(f"âœ“ Generation {self.generation_id[:8]}... marked as completed")
            except Exception as e:
                print(f"âš  Failed to mark generation as completed: {e}")

        return {
            'analysis_path': analysis_path,
            'variants_generated': list(final_ads.keys()),
            'final_ads': final_ads,
            'evaluations': evaluations,
            'elapsed_time': elapsed
        }


# Main execution
if __name__ == "__main__":
    import sys

    cloner = AdCloner()

    if len(sys.argv) > 1:
        video_path = sys.argv[1]
    else:
        video_path = input("Enter path to winning ad video: ")

    # Optional: specify which variants to generate
    variant_choice = input("\nGenerate all variants? (y/n, default=y): ").lower()

    if variant_choice == 'n':
        print("\nAvailable variants:")
        print("  1. soft - Calm, educational")
        print("  2. medium - Professional, balanced")
        print("  3. aggressive - Urgent, intense")
        print("  4. ultra - Confrontational, disruptive")
        selected = input("Enter comma-separated numbers (e.g., 1,3): ")
        variant_map = ['soft', 'medium', 'aggressive', 'ultra']
        variants = [variant_map[int(i)-1] for i in selected.split(',') if i.strip().isdigit()]
    else:
        variants = None

    # Run pipeline
    results = cloner.clone_ad(video_path, variants)

    # Save results
    results_path = Config.OUTPUT_DIR / 'results.json'
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nResults saved to: {results_path}")
